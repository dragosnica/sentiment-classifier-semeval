@misc{twokenize,
title = {Twokenize module for tweet tokenization},
URL = {https://github.com/myleott/ark-twokenize-py}
}

@misc{spelling_corrector,
title = {How to Write a Spelling Corrector},
author = {Peter Norvig}, 
URL = {https://norvig.com/spell-correct.html}
}

@misc{glove_twitter,
title = {GloVe: Global Vectors for Word Representation},
author = {Jeffrey Pennington, Richard Socher, Christopher D. Manning},
URL = {https://nlp.stanford.edu/projects/glove/}
}

@article{cnn_sent_classification,
  author    = {Ye Zhang and
               Byron C. Wallace},
  title     = {A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional
               Neural Networks for Sentence Classification},
  journal   = {CoRR},
  volume    = {abs/1510.03820},
  year      = {2015},
  url       = {http://arxiv.org/abs/1510.03820},
  archivePrefix = {arXiv},
  eprint    = {1510.03820},
  timestamp = {Mon, 13 Aug 2018 16:47:49 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhangW15b},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{BB_twtr_at_semeval,
    title = "{BB}{\_}twtr at {S}em{E}val-2017 Task 4: Twitter Sentiment Analysis with {CNN}s and {LSTM}s",
    author = "Cliche, Mathieu",
    booktitle = "Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S17-2094",
    doi = "10.18653/v1/S17-2094",
    pages = "573--580",
    abstract = "In this paper we describe our attempt at producing a state-of-the-art Twitter sentiment classifier using Convolutional Neural Networks (CNNs) and Long Short Term Memory (LSTMs) networks. Our system leverages a large amount of unlabeled data to pre-train word embeddings. We then use a subset of the unlabeled data to fine tune the embeddings using distant supervision. The final CNNs and LSTMs are trained on the SemEval-2017 Twitter dataset where the embeddings are fined tuned again. To boost performances we ensemble several CNNs and LSTMs together. Our approach achieved first rank on all of the five English subtasks amongst 40 teams.",
}