\relax 
\citation{twokenize}
\citation{spelling_corrector}
\citation{glove_twitter}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{sec:introduction}{{I}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Text Preprocessing}{1}}
\newlabel{sec:preprocessing}{{II}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Tokenization}{1}}
\newlabel{subsec:tokenization}{{\unhbox \voidb@x \hbox {II-A}}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Pattern matching}{1}}
\newlabel{subsec:pattern_matching}{{\unhbox \voidb@x \hbox {II-B}}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Text normalization}{1}}
\newlabel{subsec:text_norm}{{\unhbox \voidb@x \hbox {II-C}}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Word Embeddings}{1}}
\newlabel{sec:embeddings}{{III}{1}}
\citation{cnn_sent_classification}
\citation{cnn_sent_classification}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Baseline models}{2}}
\newlabel{sec:baselines}{{IV}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Baselines + TF-IDF}{2}}
\newlabel{baselines_tfidf}{{\unhbox \voidb@x \hbox {IV-A}}{2}}
\newlabel{eq:convolution}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Baselines + averaged word embeddings}{2}}
\newlabel{baselines_we}{{\unhbox \voidb@x \hbox {IV-B}}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Convolutional Neural Network}{2}}
\newlabel{sec:CNN}{{V}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Input layer}{2}}
\newlabel{subsec:input_layer_cnn}{{\unhbox \voidb@x \hbox {V-A}}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Convolutional layer}{2}}
\newlabel{subsec:conv_layer_cnn}{{\unhbox \voidb@x \hbox {V-B}}{2}}
\newlabel{eq:convolution}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Training and regularization}{2}}
\newlabel{subsec:training_cnn}{{\unhbox \voidb@x \hbox {V-C}}{2}}
\citation{BB_twtr_at_semeval}
\citation{BB_twtr_at_semeval}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Architecture prototype of the CNN model. Final model also includes a fully connected layer before the softmax function. Original image is from Zhang and Wallace, 2015 \cite  {cnn_sent_classification}}}{3}}
\newlabel{fig:cnn_arch}{{1}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Long Short-Term Memory Network}{3}}
\newlabel{sec:LSTM}{{VI}{3}}
\newlabel{eq:convolution}{{3}{3}}
\newlabel{eq:lstm1}{{4}{3}}
\newlabel{eq:lstm2}{{5}{3}}
\newlabel{eq:lstm3}{{6}{3}}
\newlabel{eq:lstm4}{{7}{3}}
\newlabel{eq:lstm5}{{8}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-A}}Input layer}{3}}
\newlabel{subsec:input_layer_lstm}{{\unhbox \voidb@x \hbox {VI-A}}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Architecture of the LSTM model. Final model also includes a fully connected layer before the softmax function. Original image is from Mathieu Cliche, 2017 \cite  {BB_twtr_at_semeval}}}{4}}
\newlabel{fig:lstm_arch}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-B}}LSTM layers}{4}}
\newlabel{subsec:lstm_layers}{{\unhbox \voidb@x \hbox {VI-B}}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Stacking CNN + LSTM ensemble}{4}}
\newlabel{sec:ensemble}{{VII}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Comparison table for the baseline models}}{4}}
\newlabel{table:baseline_results}{{I}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Results}{4}}
\newlabel{sec:results}{{VIII}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VIII-A}}Baselines}{4}}
\newlabel{subsec:baseline_results}{{\unhbox \voidb@x \hbox {VIII-A}}{4}}
\bibstyle{IEEEtran}
\bibdata{semeval-tweets-report}
\bibcite{twokenize}{1}
\bibcite{spelling_corrector}{2}
\bibcite{glove_twitter}{3}
\bibcite{cnn_sent_classification}{4}
\bibcite{BB_twtr_at_semeval}{5}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Comparison table for the CNN, LSTM and ensemble networks}}{5}}
\newlabel{table:nn_results}{{II}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VIII-B}}CNN, LSTM and ensemble models}{5}}
\newlabel{subsec:cnn_lstm_results}{{\unhbox \voidb@x \hbox {VIII-B}}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IX}Discussion and summary}{5}}
\newlabel{sec:summary}{{IX}{5}}
\@writefile{toc}{\contentsline {section}{References}{5}}
